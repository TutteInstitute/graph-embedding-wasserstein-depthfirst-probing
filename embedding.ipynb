{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3b76449-2d95-4567-b415-2755865b5057",
   "metadata": {},
   "source": [
    "<span style=\"font-size: xx-large; font-weight: bold;\">Graph embedding by Wasserstein similarity of clouds of depth-first probes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a63f00-3d21-4962-ab8f-406e57be7471",
   "metadata": {},
   "source": [
    "Paul Burkhardt, Michael Gegick and Benoit Hamelin<br>\n",
    "November 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c38a5b-4caa-4997-a51d-0239e60e366c",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eed75c-11c1-45e7-846e-f41ad64e5f75",
   "metadata": {},
   "source": [
    "We seek to embed graphs in a vector space, in order to assess their similarity.\n",
    "We take inspiration from the Word2Vec word embedding, which represents each word as a distribution of random walks on a semantic similarity graph starting from this word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6645d21-5bbc-409c-a7f9-453d6a9a6e78",
   "metadata": {},
   "source": [
    "Our focus here is that of an undirected graph $G=(V,E)$.\n",
    "We consider no edge weighting nor any value mapping to vertices: simple, naked graphs, but with each vertex being associated to an index from 0 to $|V|-1$.\n",
    "We propose to characterize a graph by a distribution of local observations of its topological structure.\n",
    "This observation takes the form of a *probe*: a depth-first walk on the graph initiated at some starting vertex $v \\in V$, limited to a maximum number of hops $M$.\n",
    "Let the probe be a sequence&nbsp;$p^v \\in \\mathbb{N}^M$, where $p^v_i$ constitutes the number of hops away from $v$ after $i$ steps into the depth-first walk; $p^v_0=0$.\n",
    "The walk takes a dive hop to any vertex only once.\n",
    "Given a choice between many vertices to dive towards, the walk dives to the vertex with smallest index.\n",
    "If all the deepward neighbors of a vertex $w$ have been visited, the walk takes a surfacing hop back along the path it dove on to get to $w$ at once.\n",
    "The walk terminates under either one of two conditions:\n",
    "\n",
    "1. The walk has surfaced back to vertex $v$, where it started, after a number of hops $n < M$: we then *pad* the walk by setting $p^v_j = -1$ for $n < j < M$;\n",
    "1. The walk has performed $M$ steps in total."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536ca226-0dd1-45ef-b09f-57e91807b1b7",
   "metadata": {},
   "source": [
    "We propose to take $0 < N \\leq |V|$ such probes, each time starting from a distinct vertex sampled from a uniform distribution over the vertices not yet probed from.\n",
    "The resulting vectors of hop distances from their starting points are distinguished through a Levenshtein metric.\n",
    "Given that the probes taken from distinct vertices may be identical under certain conditions of local graph symmetry,\n",
    "the set of probes&nbsp;$P_N \\subset \\mathbb{N}^M$ is such that $|P_N| \\leq N$.\n",
    "Each probe $p \\in P_N$ is thus associated to a frequency of occurences&nbsp;$\\nu_p \\in \\mathbb{N}, \\nu_p \\leq 1, \\sum_{p\\in P_N} \\nu_p = N$.\n",
    "We may thus represent the result of probing the graph $G$ as a distribution&nbsp;$d[G, P_N]$ such that\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "d[G, P_N]:\\: & \\mathbb{N}^M & \\rightarrow & \\mathbb{R} \\\\\n",
    "             & p            & \\mapsto     & \\sum_{p \\in P_N} \\frac{\\nu_p}{N} \\delta(p - p^v)\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "where&nbsp;$\\delta(p)$ is the Dirac impulse function defined on $\\mathbb{N}^M$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369fecde-8503-4007-89a6-52cc09f1dd14",
   "metadata": {},
   "source": [
    "We assume that these distributions belong to a metric space where probes are related by the Levenshtein distance.\n",
    "This thus determines a characterization of a set of graphs by their corresponding distributions, which belong into a metric space where objects are related by the Wasserstein distance.\n",
    "The following code demonstrates how this vector space embedding may be implemented, and provides limited sanity checks in lieu of validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c96b07-505d-4aca-ba8e-9431903a8aed",
   "metadata": {},
   "source": [
    "# Imports and extension setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acf52f5-699f-4267-91bd-131d80fd7276",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from bokeh.io import output_notebook, show\n",
    "from concurrent.futures import as_completed\n",
    "import functools as ft\n",
    "import itertools as it\n",
    "import joblib as jl\n",
    "import logging as lg\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numba\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing as pre\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import *\n",
    "from umap import UMAP\n",
    "import umap.plot as up\n",
    "from vectorizers import (\n",
    "    WassersteinVectorizer,\n",
    "    ApproximateWassersteinVectorizer,\n",
    "    SinkhornVectorizer,\n",
    ")\n",
    "from xxhash import xxh64_intdigest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d553e97-5c94-4ca0-a6dc-eb379989c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa452af-a073-429b-a113-0079132d0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg.basicConfig(\n",
    "    format=\"%(asctime)s | %(levelname)-8s | %(name)15s | %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\",\n",
    "    level=lg.WARNING\n",
    ")\n",
    "lg.getLogger(\"graphs2vecs\").setLevel(lg.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a19062-e36c-4b79-afcc-fe7085221f49",
   "metadata": {},
   "source": [
    "# Probing graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec494936-ec07-456f-bafd-78f7cc9a9bbb",
   "metadata": {},
   "source": [
    "Probes will be stored as integer Numpy arrays.\n",
    "However, such arrays are not _hashable_ in the Python sense, although this is very convenient for assembling distributions.\n",
    "We will thus wrap these arrays in a bespoke `Probe` class, which provides hashing and a less pedantic equality comparison (which stands thanks to our arrays being composed of integers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e718ddf-c4f3-4df8-9e2c-94e576f3497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Probe(np.ndarray):\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        return xxh64_intdigest(self)\n",
    "\n",
    "    def __eq__(self, other: Any) -> bool:\n",
    "        if not isinstance(other, Probe):\n",
    "            return False\n",
    "        return hash(self) == hash(other)\n",
    "\n",
    "\n",
    "def mkprobe(dists: List[int]) -> Probe:\n",
    "    return np.array(dists, dtype=int).view(Probe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec99d98-fe94-4542-9056-7598a88aaa1f",
   "metadata": {},
   "source": [
    "The following routine articulates the walk algorithm expressed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c58543f-bf39-43b3-91f0-c78b64f8f250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probe_depth_first(g: nx.Graph, vertex_start: int, max_length: int) -> Probe:\n",
    "    visit = []\n",
    "    visited = {vertex_start}\n",
    "    stack = [vertex_start]\n",
    "    while len(visit) < max_length and stack:\n",
    "        visit.append(len(stack) - 1)\n",
    "        for neighbor in g.neighbors(stack[-1]):\n",
    "            if neighbor not in visited:\n",
    "                visited.add(neighbor)\n",
    "                stack.append(neighbor)\n",
    "                break\n",
    "        else:\n",
    "            stack.pop()\n",
    "\n",
    "    return mkprobe(visit + [-1] * (max_length - len(visit)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3217f7c3-3c3b-4e3b-a899-3763c42f68f4",
   "metadata": {},
   "source": [
    "We mean to probe a graph multiple times, which as was evoked, results in the same probe vector being generated from symmetrical starting vertices.\n",
    "Once all probes have been computed for a graph, we thus group them and count their multiplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00c4761-eb6d-4752-84ea-43842018b09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probe_graph(\n",
    "    g: nx.Graph,\n",
    "    max_length: int,\n",
    "    num_probes: int = 0,\n",
    "    num_jobs: int = 1\n",
    ") -> Iterator[Tuple[int, Probe]]:\n",
    "    N = nx.number_of_nodes(g)\n",
    "    if num_probes < 1 or num_probes > N:\n",
    "        num_probes = N\n",
    "    probes = sorted(\n",
    "        jl.Parallel(n_jobs=num_jobs)(\n",
    "            jl.delayed(probe_depth_first)(g, v, max_length)\n",
    "            for v in np.random.choice(g.nodes, size=num_probes, replace=False)\n",
    "        ),\n",
    "        key=hash\n",
    "    )\n",
    "\n",
    "    for _, i_probes in it.groupby(probes, key=hash):\n",
    "        probes = list(i_probes)\n",
    "        assert probes\n",
    "        yield len(probes), probes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c24e69-f88f-448e-8e91-813fdc6d49bb",
   "metadata": {},
   "source": [
    "# From probes to distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02174437-a992-4f6b-b7d7-0fee5f4398f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProbeDistribution = Tuple[np.ndarray, Sequence[np.ndarray]]\n",
    "TrackerProgress = Callable[..., Iterator]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a7bc36-dcc9-44f6-a7f5-ac7615ad1aa5",
   "metadata": {},
   "source": [
    "Now, probes even repeat over a set of graphs, further establishing the notion of the distribution as a great characterization for tracking their similarity.\n",
    "The following routines tracks the set of probes computed out of a set of graphs, providing both the distribution frequencies (the critical $\\nu_p$ parameters) and the set of probes shared among the graphs.\n",
    "\n",
    "A note here regarding probe length: it is obvious that a depth-first walk that dives to a node no more than once has maximum useful length determined by the number of nodes to the graph.\n",
    "At this step, where all the graphs involved in a similarity analysis task are provided, it is useful to provide this limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357d6e0c-9359-4dfb-9e23-99b56bab2529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphs_as_distributions_probes(\n",
    "    graphs: Sequence[nx.Graph],\n",
    "    max_length: int = 0,\n",
    "    num_probes: int = 0,\n",
    "    num_jobs: int = 1,\n",
    "    tqdm: TrackerProgress = lambda x, *_a, **_k: iter(x)\n",
    ") -> ProbeDistribution:\n",
    "    M = 2 * max(nx.number_of_nodes(g) for g in graphs) - 1\n",
    "    if max_length < 2 or max_length > M:\n",
    "        max_length = M\n",
    "\n",
    "    index_probes = {}\n",
    "    probes = []\n",
    "    #weights = np.zeros((len(graphs), 0))\n",
    "    weights = {}\n",
    "    for i, g in enumerate(tqdm(graphs, desc=\"Graph probing\")):\n",
    "        weights[i] = {}\n",
    "        for n, probe in probe_graph(g, max_length=max_length, num_probes=num_probes, num_jobs=num_jobs):\n",
    "            if probe in index_probes:\n",
    "                j = index_probes[probe]\n",
    "            else:\n",
    "                j = len(index_probes)\n",
    "                index_probes[probe] = j\n",
    "                probes.append(probe)\n",
    "            weights[i][j] = float(n)\n",
    "            # distributions[i, j] = float(n)\n",
    "\n",
    "    distributions = np.zeros((len(graphs), len(probes)))\n",
    "    for i, weights_probes_graph in weights.items():\n",
    "        for j, weight in weights_probes_graph.items():\n",
    "            distributions[i, j] = weight\n",
    "    return pre.normalize(distributions, axis=1, norm=\"l1\"), probes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd6050-f969-4882-9d07-18e3086dd548",
   "metadata": {},
   "source": [
    "# From distributions to a vector space embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de3b82-8022-43e3-b263-cea9b1475e6b",
   "metadata": {},
   "source": [
    "We propose that the probes making up a distribution should be inscribed in a metric space based on the Levenshtein distance.\n",
    "Here is a good Numba implementation ripped from [the Internet](https://gist.github.com/tuxedocat/fb024dfa36648797084d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53954f3-13f7-4f00-a80e-ebda8764da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def _levenshtein(x, y):\n",
    "    \"\"\" Levenshtein distance\n",
    "          using Dynamic-Programming strategy\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : np.array of string\n",
    "    Returns\n",
    "    -------\n",
    "    int : distance\n",
    "    np.array : distance matrix\n",
    "    \"\"\"\n",
    "    # Initiallize DP-matrix\n",
    "    D = np.zeros((len(x) + 1, len(y) + 1), dtype=np.int64)\n",
    "    D[0, 1:] = np.arange(1, len(y) + 1)\n",
    "    D[1:, 0] = np.arange(1, len(x) + 1)\n",
    "\n",
    "    for i in range(1, len(x) + 1):\n",
    "        for j in range(1, len(y) + 1):\n",
    "            delta = 2 if x[i - 1] != y[j - 1] else 0\n",
    "            D[i, j] = min(D[i - 1, j - 1] + delta, D[i - 1, j] + 1, D[i, j - 1] + 1)\n",
    "    return D[-1, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45043147-0568-48e1-a8c0-37ff737349da",
   "metadata": {},
   "source": [
    "This metric space enables us to embed the distributions themselves into their own metric space based on the Wasserstein distance.\n",
    "This gives us an end-to-end routine that takes a set of graphs and probing parameters, and yields a corresponding set of vectors (embedded in a Euclidean metric space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571a5fa1-ffc4-4c47-812f-6820d1302e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphs2vecs(\n",
    "    graphs: Sequence[nx.Graph],\n",
    "    max_length: int = 0,\n",
    "    num_probes: int = 0,\n",
    "    num_jobs: int = 1,\n",
    "    tqdm: TrackerProgress = lambda x, *_, **__: iter(x),\n",
    "    vectorizer: Type = WassersteinVectorizer,\n",
    "    **args_wv\n",
    ") -> np.ndarray:\n",
    "    LOG = lg.getLogger(\"graphs2vecs\")\n",
    "    LOG.info(\"Probe the graphs\")\n",
    "    distributions, probes = graphs_as_distributions_probes(\n",
    "        graphs,\n",
    "        max_length=max_length,\n",
    "        num_probes=num_probes,\n",
    "        num_jobs=num_jobs,\n",
    "        tqdm=tqdm\n",
    "    )\n",
    "\n",
    "    args_wv[\"n_components\"] = max(\n",
    "        args_wv.get(\"n_components\", 0),\n",
    "        2 * max(len(v) for v in probes)\n",
    "    )\n",
    "    args_wv.setdefault(\"metric\", _levenshtein)\n",
    "    LOG.info(\"Calculate Wasserstein vectorization\")\n",
    "    return WassersteinVectorizer(**args_wv).fit_transform(\n",
    "        distributions,\n",
    "        vectors=probes\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334785d6-d861-4742-b192-8f874d3bc789",
   "metadata": {},
   "source": [
    "# Eyeballing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eea3af1-de83-4afe-8fae-3df56c62b4f3",
   "metadata": {},
   "source": [
    "While we are interested in embedding quite large graphs with this approach, this first implementation leverages unoptimized, easy-to-use tools.\n",
    "As such, I surmise that this code would not be snappy with graphs as small as the 500-vertex range.\n",
    "So let's instead examine the embeddings of a subset of the small graphs that make up NetworkX's graph atlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139282e4-3106-4552-a798-dfd5f1e60151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_atlas(min_nodes, min_edges, min_nodes_per_cc):\n",
    "    return [\n",
    "        g\n",
    "        for g in nx.graph_atlas_g()\n",
    "        if (\n",
    "            nx.number_of_nodes(g) >= min_nodes\n",
    "            and nx.number_of_edges(g) >= min_edges\n",
    "            and all(len(cv) >= min_nodes_per_cc for cv in nx.connected_components(g))\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1158e7e5-c952-4a76-a6bc-411f8f45c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "atlas = gen_atlas(4, 3, 2)\n",
    "len(atlas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97ebae4-3077-49f8-bb9c-8eda33cd81a9",
   "metadata": {},
   "source": [
    "What do these look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5d7275-7c08-44f8-92ab-7215681617e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_from_atlas(*i_graphs, num_cols: int = 15, width: float = 20.0):\n",
    "    if not i_graphs:\n",
    "        i_graphs = range(len(atlas))\n",
    "    num_cols = min(len(i_graphs), num_cols)\n",
    "    q, r = divmod(len(i_graphs), num_cols)\n",
    "    num_rows = q + min(r, 1)\n",
    "    plt.figure(figsize=(width, 1.1 * width * num_rows / num_cols))\n",
    "\n",
    "    for i, ig in enumerate(i_graphs, start=1):\n",
    "        plt.subplot(num_rows, num_cols, i)\n",
    "        g = atlas[ig]\n",
    "        plt.title(f\"{ig}: |V|={nx.number_of_nodes(g)} |E|={nx.number_of_edges(g)}\", fontsize=6)\n",
    "        nx.draw(g, node_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e41aa66-36ef-44ea-ab66-7dfe142a8e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "draw_from_atlas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faec689e-aa21-4593-b42f-54ad7486ab2e",
   "metadata": {},
   "source": [
    "These graphs are composed of no more than 7 vertices, we insist on having a non-trivial edge set, and we restrict connected components to carry at least two vertices.\n",
    "In this situation, most of these graphs look very similar from the structural perspective we have taken.\n",
    "Each graph admits at most 7 distinct probes: let's make them long enough to ensure that each can cover all of a unique connected component.\n",
    "Before we compute vectors, let's look at how many distinct probes characterize our 1000ish graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4235aa86-b5c6-4a1f-a0f7-9844daad5f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "distr, probes = graphs_as_distributions_probes(atlas)\n",
    "len(probes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4892e0c-7ea7-432b-b833-634740fc4137",
   "metadata": {},
   "source": [
    "So the \"vocabulary\" that describes each graph is composed of less than 20% the number of graphs themselves.\n",
    "I believe the situation would be quite different from the large graph embedding being considered as target application for this approach.\n",
    "The number of edges in such cases would be such that it would be very unlikely to hop over all of them, unless one would afford a large number of long probes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e5c2b4-1b9c-4222-8992-12572d90eda9",
   "metadata": {},
   "source": [
    "Let's embed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52cac18-4312-4f13-8bab-f383eb7ffdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "emb = graphs2vecs(atlas, n_components=128, tqdm=tqdm)\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0df84e-c63c-4273-92e6-83cefc553b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "u = UMAP()\n",
    "u.fit_transform(emb)\n",
    "num_vertices = np.array([nx.number_of_nodes(g) for g in atlas])\n",
    "up.points(u, labels=num_vertices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b49984-b3eb-4583-a67c-51c656e30d42",
   "metadata": {},
   "source": [
    "The embedding structure largely reflects the number of vertices, with smaller graphs congregating together, and 7-vertex graphs showing multiple modes of similarity.\n",
    "To investigate further, one is welcome to use an interactive plot (no, it's not [This Not That](https://github.com/TutteInstitute/thisnotthat/)),\n",
    "and to use the `draw_from_atlas` function to puzzle visually why graphs are considered similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4fb87d-2482-4e32-aed1-3e963103b6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(\n",
    "    up.interactive(\n",
    "        u,\n",
    "        labels=num_vertices,\n",
    "        hover_data=pd.DataFrame([\n",
    "            {\"i\": i, \"|V|\": nx.number_of_nodes(g), \"|E|\": nx.number_of_edges(g)}\n",
    "            for i, g in enumerate(atlas)\n",
    "        ])\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9bc354-88f9-4f60-a959-a3f149310561",
   "metadata": {},
   "source": [
    "Why are these guys bunched up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6ade8e-9fe7-4221-b69f-ab6d6425f9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_from_atlas(6, 29, 151)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186e0e9f-d4e4-4307-9834-6e7f6bafcff1",
   "metadata": {},
   "source": [
    "Oooh monomorphisms across disconnected components!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dd861a-d4e8-45a3-81ef-6c5573a6564b",
   "metadata": {},
   "source": [
    "Why these similar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fa5ecf-db6d-4777-8e9d-473b363d0813",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_from_atlas(0, 4, 210, 291)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12bb072-60f0-433f-a9a1-c6d457b5530b",
   "metadata": {},
   "source": [
    "Ah, good old fork, it's everywhere... but it will not share probes unless it's disconnected!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd6a3e6-8f20-4748-a4fe-b4818e6d55d0",
   "metadata": {},
   "source": [
    "Why two very distant clumps of 6-vertex graphs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33270f28-c4e5-416c-85a3-6e279687f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_from_atlas(141, 142, 144, 146, 64, 87, 120, 133, num_cols=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72be58d9-90b3-475a-8e27-6eb7a94d1669",
   "metadata": {},
   "source": [
    "Less clear: the graphs on the lower row are less connected, but 133 looks a lot like 142.\n",
    "More to dig out from analyzing the list of probes: it seems that adding one more edge at this scale changes the walk significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f568b57-c81b-4bc3-9b9b-7d6c70d86e6d",
   "metadata": {},
   "source": [
    "Finally, a comparison of samples from two very distant cluster of 7-vertex graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9206f849-bd83-4297-969b-02996bc8bf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_from_atlas(734, 883, 639, 733, 521, 642, 797, 935, num_cols=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c06770-b549-42a1-a973-baf4ff1d2449",
   "metadata": {},
   "source": [
    "The lower row does present some more connectivity, but it's long past my bedtime and I can't get myself to unpack what's going on with much more seriousness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd07ca8-368f-4e8d-bd71-7839115ec533",
   "metadata": {},
   "source": [
    "# Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04cc229-feb8-4c73-b1bc-d49ba740a310",
   "metadata": {},
   "source": [
    "Things seem to work for small graphs, and the outlook for larger graphs seems good to me.\n",
    "\n",
    "Issues:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68a8d6f-3c67-4aa3-9916-507ed34f0def",
   "metadata": {},
   "source": [
    "- The Levenshtein distance is expensive...\n",
    "    Is there a way to approximate it, or to take advantage of the very particular shape of the probes?\n",
    "    They are integer sequences that increase or decrease by one at every step.\n",
    "- The nominal Wasserstein vectorizer is slow, and we have two alternatives we could bring into play to deal with larger distributions and larger sets of graphs to co-embed. Let's try to substitute them in place over the `WassersteinVectorizer` class.\n",
    "- Paul has raised that the probe length one should choose could probably be obtained by solving some form of a Coupon Collector problem.\n",
    "- Can the number of probes to compose into a distribution be chosen in this way, alternatively?\n",
    "- Compare further against other graph embedding techniques: [ReFEx](https://github.com/benedekrozemberczki/RolX) ([paper](https://dl.acm.org/doi/10.1145/2020408.2020512)), graph neural nets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b6755f-f61b-451a-9658-d451aa0fe867",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc2875f-c610-480c-9abf-851c23825e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc3126-ab8d-4870-b1ce-b9f91d71a746",
   "metadata": {},
   "outputs": [],
   "source": [
    "NCI = \"NCI109\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c423083-ae3d-4e17-8942-99d7c49625b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent = Path(NCI)\n",
    "path_edges = parent / f\"{NCI}_A.txt\"\n",
    "path_graphs = parent / f\"{NCI}_graph_indicator.txt\"\n",
    "path_labels = parent / f\"{NCI}_graph_labels.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4543644e-2a5c-4fc5-8713-17d2fdd95d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.read_csv(path_graphs, names=[\"graph\"])\n",
    "nodes[\"node\"] = range(1, len(nodes) + 1)\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ffa40e-9daa-42e8-ae0e-740fea07d395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd040ed4-6830-4299-af0d-fa2623c0e2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "node2graph = defaultdict(lambda: nodes[\"graph\"].max(), {n: g for n, g in nodes[[\"node\", \"graph\"]].itertuples(index=False)})\n",
    "len(node2graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c37124d-f4b4-4c76-ad75-22b943d56378",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = pd.read_csv(path_edges, names=[\"from\", \"to\"])\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f2bde3-3403-4cae-bd34-29e3acb8785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges[\"graph\"] = edges[\"from\"].map(node2graph, na_action=None)\n",
    "edges[\"graph_\"] = edges[\"to\"].map(node2graph, na_action=None)\n",
    "edges[\"agree\"] = (edges[\"graph\"] == edges[\"graph_\"])\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65927951-5a16-46ee-8305-09d1ef57ae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert edges.loc[~edges[\"agree\"]].empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ae6e7e-1b4a-4157-be98-a72f1d7c074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "graphs = {}\n",
    "for graph, _group in tqdm(iter(edges.groupby(\"graph\")), total=nodes[\"graph\"].nunique()):\n",
    "    graphs[graph] = nx.Graph()\n",
    "    graphs[graph].add_edges_from([(f, t) for f, t in _group[[\"from\", \"to\"]].itertuples(index=False)])\n",
    "len(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5292579-0800-4c83-a82f-28295fb6f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm as tqdm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b9e6f1-aceb-40b2-a040-65557a4d8ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "kv_graphs = list(graphs.items())\n",
    "emb = graphs2vecs([g for _, g in kv_graphs], max_length=50, num_probes=50, num_jobs=-1, n_components=128, tqdm=tqdm, metric=\"l1\")\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6829d622-c03c-4bac-b6f8-d96b0bb29cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6719090-4377-4fc3-aba6-71f617adb832",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "u2 = umap.UMAP(n_components=2, metric=\"cosine\", verbose=True).fit(emb)\n",
    "u2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecd84d6-3bab-4b0d-a4d8-310a73d20da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame({\n",
    "    \"graph\": range(1, len(graphs) + 1),\n",
    "    \"class\": pd.read_csv(path_labels, names=[\"class\"])[\"class\"]\n",
    "}).set_index(\"graph\")[\"class\"]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47dfd77-84d1-489c-8f02-ac3a5eb27c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = up.interactive(u2, labels=labels.loc[[i for i, _ in kv_graphs]], width=1200, height=1200, point_size=5, theme=\"red\")\n",
    "up.show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310143af-fd41-47cd-99ea-70229a6eb4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Depth-first probe graph embedding",
   "language": "python",
   "name": "dfs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
